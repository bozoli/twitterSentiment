{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../training.1600000.processed.noemoticon.csv', encoding='iso-8859-1', header=None, names=['Sentiment','Id', 'Date', 'Query', 'User', 'Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Query</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment          Id                          Date     Query  \\\n",
       "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              User                                               Text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['Id','Query','User','Date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                               Text\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1          0  is upset that he can't update his Facebook by ...\n",
       "2          0  @Kenichan I dived many times for the ball. Man...\n",
       "3          0    my whole body feels itchy and like its on fire \n",
       "4          0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "#from nltk.corpus import stopwords\n",
    "\n",
    "#create an object of class PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "#edited_stop_words = [re.sub('[\\']+', '',word) for word in stopwords.words('english')]\n",
    "\n",
    "auxiliaryVerbs = ['do','does','did','has','have','had','should','must','can','could']\n",
    "splitNegativeWords = re.compile(r'('+r'|'.join(auxiliaryVerbs)+r')n?\\'t')\n",
    "\n",
    "def prepare_tweet(tweet_text):\n",
    "    # Removing Hashtags\n",
    "    tweet_aux = re.sub('(^|\\ )#[^ ]+', '', str.lower(tweet_text))\n",
    "    # Removing mentions\n",
    "    tweet_aux = re.sub('(^|\\ )@[^ ]+', '', tweet_aux)\n",
    "    # Removing URLs\n",
    "    tweet_aux =  re.sub('https?://[^ ]+', '', tweet_aux)\n",
    "    tweet_aux =  re.sub('www.[^ ]+', '', tweet_aux)\n",
    "    # Removing symbols and numbers\n",
    "    tweet_aux = re.sub('[^A-Za-z \\n]+', '', tweet_aux)\n",
    "    ## Remove stopwords - Commented because resulted in a worse accuracy\n",
    "    ## tweet_aux =  [word for word in tweet.split() if word not in edited_stop_words]\n",
    "    # Splitting contracted negative auxiliary verbs\n",
    "    tweet_aux = splitNegativeWords.sub(\"\\\\1 not\", tweet_aux)\n",
    "    # Stemming\n",
    "    stem_tokens = []\n",
    "    for token in tweet_aux.split():\n",
    "        stem_tokens.append(porter.stem(token))\n",
    "    return ' '.join(stem_tokens)\n",
    "\n",
    "#pattern_mentions = re.compile(\"(^|\\ )@[A-Za-z0-9\\-_]+\")\n",
    "#\n",
    "#def is_there_mentions(tweet):\n",
    "#    if pattern_mentions.search(tweet):\n",
    "#        return 1\n",
    "#    else:\n",
    "#        return 0\n",
    "#\n",
    "#def num_words(processed_tweet):\n",
    "#    return len(processed_tweet.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_rows = 1000000\n",
    "train_sample = pd.concat([train[0:int(number_rows/2)].copy(),train[800000:800000+int(number_rows/2)].copy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 2, 19, 15, 26, 35, 614655)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample['Tokens'] = train_sample['Text'].apply(prepare_tweet)\n",
    "# train_sample['Mentions'] = train_sample['Text'].apply(is_there_mentions)\n",
    "# train_sample['Num_words'] = train_sample['Tokens'].apply(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>awww that a bummer you shoulda got david carr ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>is upset that he cant updat hi facebook by tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>i dive mani time for the ball manag to save th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>my whole bodi feel itchi and like it on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>no it not behav at all im mad whi am i here be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Need a hug</td>\n",
       "      <td>need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
       "      <td>hey long time no see ye rain a bit onli a bit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "      <td>nope they didnt have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>@twittera que me muera ?</td>\n",
       "      <td>que me muera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                               Text  \\\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1          0  is upset that he can't update his Facebook by ...   \n",
       "2          0  @Kenichan I dived many times for the ball. Man...   \n",
       "3          0    my whole body feels itchy and like its on fire    \n",
       "4          0  @nationwideclass no, it's not behaving at all....   \n",
       "5          0                      @Kwesidei not the whole crew    \n",
       "6          0                                        Need a hug    \n",
       "7          0  @LOLTrish hey  long time no see! Yes.. Rains a...   \n",
       "8          0               @Tatiana_K nope they didn't have it    \n",
       "9          0                          @twittera que me muera ?    \n",
       "\n",
       "                                              Tokens  \n",
       "0  awww that a bummer you shoulda got david carr ...  \n",
       "1  is upset that he cant updat hi facebook by tex...  \n",
       "2  i dive mani time for the ball manag to save th...  \n",
       "3       my whole bodi feel itchi and like it on fire  \n",
       "4  no it not behav at all im mad whi am i here be...  \n",
       "5                                 not the whole crew  \n",
       "6                                         need a hug  \n",
       "7  hey long time no see ye rain a bit onli a bit ...  \n",
       "8                            nope they didnt have it  \n",
       "9                                       que me muera  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 2, 19, 15, 29, 48, 259760)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for word in top_words:\n",
    "#     train_sample[word] = int(word in train_sample['Tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample.reset_index(inplace=True)\n",
    "train_sample.drop(columns=['index'], axis=1, inplace=True)\n",
    "# train_sample.drop(columns=['index', 'level_0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>awww that a bummer you shoulda got david carr ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>is upset that he cant updat hi facebook by tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>i dive mani time for the ball manag to save th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>my whole bodi feel itchi and like it on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>no it not behav at all im mad whi am i here be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                               Text  \\\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1          0  is upset that he can't update his Facebook by ...   \n",
       "2          0  @Kenichan I dived many times for the ball. Man...   \n",
       "3          0    my whole body feels itchy and like its on fire    \n",
       "4          0  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                              Tokens  \n",
       "0  awww that a bummer you shoulda got david carr ...  \n",
       "1  is upset that he cant updat hi facebook by tex...  \n",
       "2  i dive mani time for the ball manag to save th...  \n",
       "3       my whole bodi feel itchi and like it on fire  \n",
       "4  no it not behav at all im mad whi am i here be...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import collections\n",
    "\n",
    "with open('./word_count_100k.csv', 'r') as csvfile: \n",
    "    w = csv.DictReader(csvfile)\n",
    "    word_count_aux = list(w)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_dict = {key:int(value) for key,value in word_count_aux.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = collections.Counter(word_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 36785),\n",
       " ('the', 32800),\n",
       " ('I', 30090),\n",
       " ('a', 23781),\n",
       " ('it', 19995),\n",
       " ('and', 18962),\n",
       " ('my', 16456),\n",
       " ('you', 16412),\n",
       " ('is', 14827),\n",
       " ('i', 14611)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = [word for (word, count) in word_count.most_common(2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 2, 19, 15, 29, 48, 572922)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer(vocabulary=top_words, token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "bag_of_words = count.transform(train_sample['Tokens'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #count = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\",ngram_range=(1,2), max_features=2000)\n",
    "# count = CountVectorizer(ngram_range=(1,2), max_features=2000)\n",
    "# bag_of_words = count.fit_transform(train_sample['Tokens'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show feature matrix\n",
    "# bow_set = bag_of_words.astype(np.int16).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 2, 19, 15, 29, 58, 377736)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w+\\\\b', tokenizer=None,\n",
       "        vocabulary=['to', 'the', 'I', 'a', 'it', 'and', 'my', 'you', 'is', 'i', 'in', 'for', 'of', 'that', 'have', 'on', 'me', 'go', 'but', 'be', 'just', 'so', 'with', 'get', 'not', 'at', 'day', 'Im', 'wa', 'work', 'thi', 'good', 'up', 'now', 'your', 'do', 'out', 'like', 'all', 'are', 'love', 'today', 'time...it', 'proper', 'yah', 'nerd', 'unfollow', 'mama', 'bubbl', 'intern', 'sweat', 'tempt', 'bah', 'msg'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag_of_words.astype(np.int16).toarray() inline to save 2GB of RAM not creating the variable bow_set\n",
    "train_sample = pd.concat([train_sample, pd.DataFrame(bag_of_words.astype(np.int8).toarray(), columns=top_words, dtype=np.int8)],sort=False,axis=1,join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = train_sample.drop(columns=['Text', 'Tokens'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(training_set.drop('Sentiment',axis=1), \n",
    "                                                    training_set['Sentiment'], test_size=0.30, \n",
    "                                                    random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logmodel = LogisticRegression(solver='lbfgs')\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 2, 19, 15, 31, 58, 446651)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.393645])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.75      0.77    150146\n",
      "          4       0.76      0.81      0.78    149854\n",
      "\n",
      "avg / total       0.78      0.78      0.78    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77847\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>to</th>\n",
       "      <th>the</th>\n",
       "      <th>I</th>\n",
       "      <th>a</th>\n",
       "      <th>it</th>\n",
       "      <th>and</th>\n",
       "      <th>my</th>\n",
       "      <th>you</th>\n",
       "      <th>is</th>\n",
       "      <th>...</th>\n",
       "      <th>yah</th>\n",
       "      <th>nerd</th>\n",
       "      <th>unfollow</th>\n",
       "      <th>mama</th>\n",
       "      <th>bubbl</th>\n",
       "      <th>intern</th>\n",
       "      <th>sweat</th>\n",
       "      <th>tempt</th>\n",
       "      <th>bah</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment  to  the  I  a  it  and  my  you  is ...   yah  nerd  unfollow  \\\n",
       "0          0   1    0  0  1   1    0   0    1   0 ...     0     0         0   \n",
       "1          0   0    0  0  1   1    1   0    0   1 ...     0     0         0   \n",
       "2          0   1    2  0  0   0    0   0    0   0 ...     0     0         0   \n",
       "3          0   0    0  0  0   1    1   1    0   0 ...     0     0         0   \n",
       "4          0   0    0  0  0   1    0   0    1   0 ...     0     0         0   \n",
       "\n",
       "   mama  bubbl  intern  sweat  tempt  bah  msg  \n",
       "0     0      0       0      0      0    0    0  \n",
       "1     0      0       0      0      0    0    0  \n",
       "2     0      0       0      0      0    0    0  \n",
       "3     0      0       0      0      0    0    0  \n",
       "4     0      0       0      0      0    0    0  \n",
       "\n",
       "[5 rows x 2001 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "def sentiment(tweet_text):\n",
    "    clean_tweet = prepare_tweet(tweet_text)\n",
    "    counter = CountVectorizer(vocabulary=top_words, token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "    tweet_bag_of_words = counter.transform([clean_tweet])\n",
    "    tweet_bow_df = pd.DataFrame(tweet_bag_of_words.astype(np.int8).toarray(), columns=top_words, dtype=np.int8)\n",
    "    return logmodel.predict(tweet_bow_df)\n",
    "\n",
    "sentiment(\"Fuck this shit Trump\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Ways to Save the Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Pickle to serialize the model and save to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(logmodel, open('twitterML.model', 'wb'), protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model coefficients to a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77847\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "logmodel3 = pickle.load(open('twitterML.model', 'rb'))\n",
    "predictions3 = logmodel3.predict(X_test)\n",
    "print(accuracy_score(y_test,predictions3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Missclassified Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds</td>\n",
       "      <td>i dive mani time for the ball manag to save the rest go out of bound</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?</td>\n",
       "      <td>hey long time no see ye rain a bit onli a bit lol im fine thank how you</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@twittera que me muera ?</td>\n",
       "      <td>que me muera</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>@angry_barista I baked you a cake but I ated it</td>\n",
       "      <td>i bake you a cake but i ate it</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>@cocomix04 ill tell ya the story later  not a good day and ill be workin for like three more hours...</td>\n",
       "      <td>ill tell ya the stori later not a good day and ill be workin for like three more hour</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>@Viennah Yay! I'm happy for you with your job! But that also means less time for me and you...</td>\n",
       "      <td>yay im happi for you with your job but that also mean less time for me and you</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>@msdrama hey missed ya at the meeting  sup mama</td>\n",
       "      <td>hey miss ya at the meet sup mama</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>wednesday my b-day! don't know what 2 do!!</td>\n",
       "      <td>wednesday my bday dont know what do</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>@stark YOU don't follow me, either  and i work for you!</td>\n",
       "      <td>you dont follow me either and i work for you</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>A bad nite for the favorite teams: Astros and Spartans lose.  The nite out with T.W. was good.</td>\n",
       "      <td>a bad nite for the favorit team astro and spartan lose the nite out with tw wa good</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>@Henkuyinepu it's overrated</td>\n",
       "      <td>it overr</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>I'm missing you babe..  but as long as your alive I'm happy.. Yawwwnn.. I'm tired my love imma try to sleep hopefully you had a headstart</td>\n",
       "      <td>im miss you babe but as long as your aliv im happi yawwwnn im tire my love imma tri to sleep hope you had a headstart</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Agh...snow!!!</td>\n",
       "      <td>aghsnow</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>@mrsaintnick hey! i'm leavin in the morning...</td>\n",
       "      <td>hey im leavin in the morn</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>@marieclr I was serious  LOL</td>\n",
       "      <td>i wa seriou lol</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>@ColinDeMar Far too out of the way for rail.  any other tips?</td>\n",
       "      <td>far too out of the way for rail ani other tip</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Staying at a friends house...house sitting, neighbors are SO loud-having a party</td>\n",
       "      <td>stay at a friend househous sit neighbor are so loudhav a parti</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Downloading NIN's new album &amp;quot;the slip&amp;quot; - when the hell did this come out? I'm so behind the times these days</td>\n",
       "      <td>download nin new album quotth slipquot when the hell did thi come out im so behind the time these day</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>@mandayyy</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>@breadandbadger Congrats!!  i totally forgot to submit photos</td>\n",
       "      <td>congrat i total forgot to submit photo</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>@charlietm I know right. I dunno what is going on with twitter.</td>\n",
       "      <td>i know right i dunno what is go on with twitter</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>@mandayyy</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>New video card is DOA.</td>\n",
       "      <td>new video card is doa</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>help me forget 8th april &amp;amp; 13th july!</td>\n",
       "      <td>help me forget th april amp th juli</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>@mathewsmichael  i agree... the jobros dont update theres very often</td>\n",
       "      <td>i agre the jobro dont updat there veri often</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>@riancurtis  i'm here, friend, and i love you.</td>\n",
       "      <td>im here friend and i love you</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>http://twitpic.com/2y2wr - according to my bro, our new puppy had a poo fight and was covered in poop  (picture stolen from him)</td>\n",
       "      <td>accord to my bro our new puppi had a poo fight and wa cover in poop pictur stolen from him</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>@JonathanRKnight Oh! Did I mention it? &amp;quot;Gooooood Moooorniiiiiiing&amp;quot;  from Germany! Im back in my cage....or better...my office</td>\n",
       "      <td>oh did i mention it quotgooooood moooorniiiiiiingquot from germani im back in my cageor bettermi offic</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>@ridley1013 I agree. The shapeshifting is a copout. I was so excited for Angela's ep, I thought it was this week.  Noah was awesome tho!</td>\n",
       "      <td>i agre the shapeshift is a copout i wa so excit for angela ep i thought it wa thi week noah wa awesom tho</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>day 2. a lot harder than day 1. let's see how day 3 goes tomorrow.</td>\n",
       "      <td>day a lot harder than day let see how day goe tomorrow</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499653</th>\n",
       "      <td>@UrbanWireTV Also, BIG FAVOR! I need your intern to hit me w/ the past interviews...I gotta send in a demo asap</td>\n",
       "      <td>also big favor i need your intern to hit me w the past interviewsi gotta send in a demo asap</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499678</th>\n",
       "      <td>@Chet_Cannon they took the panda express out of our mall. Boy I miss their orange chicken. Enjoy!!</td>\n",
       "      <td>they took the panda express out of our mall boy i miss their orang chicken enjoy</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499693</th>\n",
       "      <td>@DemonicVel Hahaha. Sorry, otherwise, I abstain. I like both.</td>\n",
       "      <td>hahaha sorri otherwis i abstain i like both</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499709</th>\n",
       "      <td>'s sides still hurt from seeing Jim Breuer at the comedy club last night.  He was awesome!</td>\n",
       "      <td>s side still hurt from see jim breuer at the comedi club last night he wa awesom</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499712</th>\n",
       "      <td>Can't believe she's really going</td>\n",
       "      <td>cant believ she realli go</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499739</th>\n",
       "      <td>YEY. Please don't stop the rain is playing now</td>\n",
       "      <td>yey pleas dont stop the rain is play now</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499753</th>\n",
       "      <td>up, up and away. so much to do before we head to camp tomorrow!</td>\n",
       "      <td>up up and away so much to do befor we head to camp tomorrow</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499757</th>\n",
       "      <td>@modalissa @croskelley I want in on that too</td>\n",
       "      <td>i want in on that too</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499769</th>\n",
       "      <td>@CookingGranny well.. two more years of highschool.. ha ha ha but done for this grade ten season</td>\n",
       "      <td>well two more year of highschool ha ha ha but done for thi grade ten season</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499771</th>\n",
       "      <td>Landed in Orlando. Drugs rule. Now to drag my weary ass all over Hells Half Acre!</td>\n",
       "      <td>land in orlando drug rule now to drag my weari ass all over hell half acr</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499789</th>\n",
       "      <td>has achy legs. I wonder why</td>\n",
       "      <td>ha achi leg i wonder whi</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499793</th>\n",
       "      <td>well .. i need to leave right now i gotta go to the dentist  &amp;amp; really miss my bed  i canï¿½t wait 4 the SatuRday!!!! need 2 see ya!!!</td>\n",
       "      <td>well i need to leav right now i gotta go to the dentist amp realli miss my bed i cant wait the saturday need see ya</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499794</th>\n",
       "      <td>@jkeyes I didn't have one to show her</td>\n",
       "      <td>i didnt have one to show her</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499806</th>\n",
       "      <td>@StaunchConserv No, you aren't wrong and it is NOT just you. You are not alone!</td>\n",
       "      <td>no you arent wrong and it is not just you you are not alon</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499816</th>\n",
       "      <td>@Evelyn_Klotz lol Don't worry about, my pillow eating ways are none of your damn business</td>\n",
       "      <td>lol dont worri about my pillow eat way are none of your damn busi</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499818</th>\n",
       "      <td>Goodmoring! I can't wait to see Danny today; we're headed to the 209!</td>\n",
       "      <td>goodmor i cant wait to see danni today were head to the</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499824</th>\n",
       "      <td>@PeepingNee Have fun at the zoo!!  I wish I could go</td>\n",
       "      <td>have fun at the zoo i wish i could go</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499827</th>\n",
       "      <td>@malcolmbastien I usually sit at the back where the comfy chairs are.</td>\n",
       "      <td>i usual sit at the back where the comfi chair are</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499836</th>\n",
       "      <td>@clothes_w don't miss 2nite's, clothes! it's the last one!  -- and totally LOL-ing at your give a h8r a hug post...amen to that!</td>\n",
       "      <td>dont miss nite cloth it the last one and total lole at your give a hr a hug postamen to that</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499853</th>\n",
       "      <td>@dcostalis that's what I'm finding</td>\n",
       "      <td>that what im find</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499861</th>\n",
       "      <td>@aussiecynic  HIII   still lost in MIN working not enjoying the city  then after work straight to the airport Chicago home bound</td>\n",
       "      <td>hiii still lost in min work not enjoy the citi then after work straight to the airport chicago home bound</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499863</th>\n",
       "      <td>@butlerfetish That's a whole lot of donuts!  I can't really care more than 2 myself.</td>\n",
       "      <td>that a whole lot of donut i cant realli care more than myself</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499877</th>\n",
       "      <td>@ladysuperastro Not tight enough</td>\n",
       "      <td>not tight enough</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499881</th>\n",
       "      <td>I'm sitting in my arm chair</td>\n",
       "      <td>im sit in my arm chair</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499923</th>\n",
       "      <td>About to go 120 mph around the road track at Watkins Glen International! Feelin' the need for SPEED</td>\n",
       "      <td>about to go mph around the road track at watkin glen intern feelin the need for speed</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499930</th>\n",
       "      <td>I was inspired by Susan Boyle from BGT thats why i did a version of her killing me softly song. She's so amazing and love her to win.</td>\n",
       "      <td>i wa inspir by susan boyl from bgt that whi i did a version of her kill me softli song she so amaz and love her to win</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499937</th>\n",
       "      <td>@DrRus lol, that's ok  I do have clothes to sell on ebay/donate, just nothing in the twins' size</td>\n",
       "      <td>lol that ok i do have cloth to sell on ebaydon just noth in the twin size</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499948</th>\n",
       "      <td>back on the Dub Pistols flex ....... fuck me Rodney P is pure fire</td>\n",
       "      <td>back on the dub pistol flex fuck me rodney p is pure fire</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499963</th>\n",
       "      <td>@alexnewson I heard Arthur Conan Doyle sent &amp;quot;We are discovered - Hide!&amp;quot; notes to 5 friends as a joke. One was never heard of again</td>\n",
       "      <td>i heard arthur conan doyl sent quotw are discov hidequot note to friend as a joke one wa never heard of again</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>@markhoppus I want to go to that Irvine show sooooo bad! It's been way too long since I've been to a Blink show.</td>\n",
       "      <td>i want to go to that irvin show sooooo bad it been way too long sinc ive been to a blink show</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33486 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                 Text  \\\n",
       "2       @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds                                                       \n",
       "7       @LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?                                             \n",
       "9       @twittera que me muera ?                                                                                                                        \n",
       "22      @angry_barista I baked you a cake but I ated it                                                                                                 \n",
       "36      @cocomix04 ill tell ya the story later  not a good day and ill be workin for like three more hours...                                           \n",
       "45      @Viennah Yay! I'm happy for you with your job! But that also means less time for me and you...                                                  \n",
       "86      @msdrama hey missed ya at the meeting  sup mama                                                                                                 \n",
       "91      wednesday my b-day! don't know what 2 do!!                                                                                                      \n",
       "98      @stark YOU don't follow me, either  and i work for you!                                                                                         \n",
       "99      A bad nite for the favorite teams: Astros and Spartans lose.  The nite out with T.W. was good.                                                  \n",
       "108     @Henkuyinepu it's overrated                                                                                                                     \n",
       "134     I'm missing you babe..  but as long as your alive I'm happy.. Yawwwnn.. I'm tired my love imma try to sleep hopefully you had a headstart       \n",
       "135     Agh...snow!!!                                                                                                                                   \n",
       "142     @mrsaintnick hey! i'm leavin in the morning...                                                                                                  \n",
       "168     @marieclr I was serious  LOL                                                                                                                    \n",
       "176     @ColinDeMar Far too out of the way for rail.  any other tips?                                                                                   \n",
       "179     Staying at a friends house...house sitting, neighbors are SO loud-having a party                                                                \n",
       "183     Downloading NIN's new album &quot;the slip&quot; - when the hell did this come out? I'm so behind the times these days                          \n",
       "208     @mandayyy                                                                                                                                       \n",
       "221     @breadandbadger Congrats!!  i totally forgot to submit photos                                                                                   \n",
       "231     @charlietm I know right. I dunno what is going on with twitter.                                                                                 \n",
       "249     @mandayyy                                                                                                                                       \n",
       "250     New video card is DOA.                                                                                                                          \n",
       "262     help me forget 8th april &amp; 13th july!                                                                                                       \n",
       "272     @mathewsmichael  i agree... the jobros dont update theres very often                                                                            \n",
       "293     @riancurtis  i'm here, friend, and i love you.                                                                                                  \n",
       "310     http://twitpic.com/2y2wr - according to my bro, our new puppy had a poo fight and was covered in poop  (picture stolen from him)                \n",
       "319     @JonathanRKnight Oh! Did I mention it? &quot;Gooooood Moooorniiiiiiing&quot;  from Germany! Im back in my cage....or better...my office         \n",
       "324     @ridley1013 I agree. The shapeshifting is a copout. I was so excited for Angela's ep, I thought it was this week.  Noah was awesome tho!        \n",
       "330     day 2. a lot harder than day 1. let's see how day 3 goes tomorrow.                                                                              \n",
       "...                                                                     ...                                                                             \n",
       "499653  @UrbanWireTV Also, BIG FAVOR! I need your intern to hit me w/ the past interviews...I gotta send in a demo asap                                 \n",
       "499678  @Chet_Cannon they took the panda express out of our mall. Boy I miss their orange chicken. Enjoy!!                                              \n",
       "499693  @DemonicVel Hahaha. Sorry, otherwise, I abstain. I like both.                                                                                   \n",
       "499709  's sides still hurt from seeing Jim Breuer at the comedy club last night.  He was awesome!                                                      \n",
       "499712  Can't believe she's really going                                                                                                                \n",
       "499739  YEY. Please don't stop the rain is playing now                                                                                                  \n",
       "499753  up, up and away. so much to do before we head to camp tomorrow!                                                                                 \n",
       "499757  @modalissa @croskelley I want in on that too                                                                                                    \n",
       "499769  @CookingGranny well.. two more years of highschool.. ha ha ha but done for this grade ten season                                                \n",
       "499771  Landed in Orlando. Drugs rule. Now to drag my weary ass all over Hells Half Acre!                                                               \n",
       "499789  has achy legs. I wonder why                                                                                                                     \n",
       "499793  well .. i need to leave right now i gotta go to the dentist  &amp; really miss my bed  i canï¿½t wait 4 the SatuRday!!!! need 2 see ya!!!       \n",
       "499794  @jkeyes I didn't have one to show her                                                                                                           \n",
       "499806  @StaunchConserv No, you aren't wrong and it is NOT just you. You are not alone!                                                                 \n",
       "499816  @Evelyn_Klotz lol Don't worry about, my pillow eating ways are none of your damn business                                                       \n",
       "499818  Goodmoring! I can't wait to see Danny today; we're headed to the 209!                                                                           \n",
       "499824  @PeepingNee Have fun at the zoo!!  I wish I could go                                                                                            \n",
       "499827  @malcolmbastien I usually sit at the back where the comfy chairs are.                                                                           \n",
       "499836  @clothes_w don't miss 2nite's, clothes! it's the last one!  -- and totally LOL-ing at your give a h8r a hug post...amen to that!                \n",
       "499853  @dcostalis that's what I'm finding                                                                                                              \n",
       "499861  @aussiecynic  HIII   still lost in MIN working not enjoying the city  then after work straight to the airport Chicago home bound                \n",
       "499863  @butlerfetish That's a whole lot of donuts!  I can't really care more than 2 myself.                                                            \n",
       "499877  @ladysuperastro Not tight enough                                                                                                                \n",
       "499881  I'm sitting in my arm chair                                                                                                                     \n",
       "499923  About to go 120 mph around the road track at Watkins Glen International! Feelin' the need for SPEED                                             \n",
       "499930  I was inspired by Susan Boyle from BGT thats why i did a version of her killing me softly song. She's so amazing and love her to win.           \n",
       "499937  @DrRus lol, that's ok  I do have clothes to sell on ebay/donate, just nothing in the twins' size                                                \n",
       "499948  back on the Dub Pistols flex ....... fuck me Rodney P is pure fire                                                                              \n",
       "499963  @alexnewson I heard Arthur Conan Doyle sent &quot;We are discovered - Hide!&quot; notes to 5 friends as a joke. One was never heard of again    \n",
       "499996  @markhoppus I want to go to that Irvine show sooooo bad! It's been way too long since I've been to a Blink show.                                \n",
       "\n",
       "                                                                                                                        Tokens  \\\n",
       "2       i dive mani time for the ball manag to save the rest go out of bound                                                     \n",
       "7       hey long time no see ye rain a bit onli a bit lol im fine thank how you                                                  \n",
       "9       que me muera                                                                                                             \n",
       "22      i bake you a cake but i ate it                                                                                           \n",
       "36      ill tell ya the stori later not a good day and ill be workin for like three more hour                                    \n",
       "45      yay im happi for you with your job but that also mean less time for me and you                                           \n",
       "86      hey miss ya at the meet sup mama                                                                                         \n",
       "91      wednesday my bday dont know what do                                                                                      \n",
       "98      you dont follow me either and i work for you                                                                             \n",
       "99      a bad nite for the favorit team astro and spartan lose the nite out with tw wa good                                      \n",
       "108     it overr                                                                                                                 \n",
       "134     im miss you babe but as long as your aliv im happi yawwwnn im tire my love imma tri to sleep hope you had a headstart    \n",
       "135     aghsnow                                                                                                                  \n",
       "142     hey im leavin in the morn                                                                                                \n",
       "168     i wa seriou lol                                                                                                          \n",
       "176     far too out of the way for rail ani other tip                                                                            \n",
       "179     stay at a friend househous sit neighbor are so loudhav a parti                                                           \n",
       "183     download nin new album quotth slipquot when the hell did thi come out im so behind the time these day                    \n",
       "208                                                                                                                              \n",
       "221     congrat i total forgot to submit photo                                                                                   \n",
       "231     i know right i dunno what is go on with twitter                                                                          \n",
       "249                                                                                                                              \n",
       "250     new video card is doa                                                                                                    \n",
       "262     help me forget th april amp th juli                                                                                      \n",
       "272     i agre the jobro dont updat there veri often                                                                             \n",
       "293     im here friend and i love you                                                                                            \n",
       "310     accord to my bro our new puppi had a poo fight and wa cover in poop pictur stolen from him                               \n",
       "319     oh did i mention it quotgooooood moooorniiiiiiingquot from germani im back in my cageor bettermi offic                   \n",
       "324     i agre the shapeshift is a copout i wa so excit for angela ep i thought it wa thi week noah wa awesom tho                \n",
       "330     day a lot harder than day let see how day goe tomorrow                                                                   \n",
       "...                                                        ...                                                                   \n",
       "499653  also big favor i need your intern to hit me w the past interviewsi gotta send in a demo asap                             \n",
       "499678  they took the panda express out of our mall boy i miss their orang chicken enjoy                                         \n",
       "499693  hahaha sorri otherwis i abstain i like both                                                                              \n",
       "499709  s side still hurt from see jim breuer at the comedi club last night he wa awesom                                         \n",
       "499712  cant believ she realli go                                                                                                \n",
       "499739  yey pleas dont stop the rain is play now                                                                                 \n",
       "499753  up up and away so much to do befor we head to camp tomorrow                                                              \n",
       "499757  i want in on that too                                                                                                    \n",
       "499769  well two more year of highschool ha ha ha but done for thi grade ten season                                              \n",
       "499771  land in orlando drug rule now to drag my weari ass all over hell half acr                                                \n",
       "499789  ha achi leg i wonder whi                                                                                                 \n",
       "499793  well i need to leav right now i gotta go to the dentist amp realli miss my bed i cant wait the saturday need see ya      \n",
       "499794  i didnt have one to show her                                                                                             \n",
       "499806  no you arent wrong and it is not just you you are not alon                                                               \n",
       "499816  lol dont worri about my pillow eat way are none of your damn busi                                                        \n",
       "499818  goodmor i cant wait to see danni today were head to the                                                                  \n",
       "499824  have fun at the zoo i wish i could go                                                                                    \n",
       "499827  i usual sit at the back where the comfi chair are                                                                        \n",
       "499836  dont miss nite cloth it the last one and total lole at your give a hr a hug postamen to that                             \n",
       "499853  that what im find                                                                                                        \n",
       "499861  hiii still lost in min work not enjoy the citi then after work straight to the airport chicago home bound                \n",
       "499863  that a whole lot of donut i cant realli care more than myself                                                            \n",
       "499877  not tight enough                                                                                                         \n",
       "499881  im sit in my arm chair                                                                                                   \n",
       "499923  about to go mph around the road track at watkin glen intern feelin the need for speed                                    \n",
       "499930  i wa inspir by susan boyl from bgt that whi i did a version of her kill me softli song she so amaz and love her to win   \n",
       "499937  lol that ok i do have cloth to sell on ebaydon just noth in the twin size                                                \n",
       "499948  back on the dub pistol flex fuck me rodney p is pure fire                                                                \n",
       "499963  i heard arthur conan doyl sent quotw are discov hidequot note to friend as a joke one wa never heard of again            \n",
       "499996  i want to go to that irvin show sooooo bad it been way too long sinc ive been to a blink show                            \n",
       "\n",
       "        Sentiment  Prediction  \n",
       "2       0          4           \n",
       "7       0          4           \n",
       "9       0          4           \n",
       "22      0          4           \n",
       "36      0          4           \n",
       "45      0          4           \n",
       "86      0          4           \n",
       "91      0          4           \n",
       "98      0          4           \n",
       "99      0          4           \n",
       "108     0          4           \n",
       "134     0          4           \n",
       "135     0          4           \n",
       "142     0          4           \n",
       "168     0          4           \n",
       "176     0          4           \n",
       "179     0          4           \n",
       "183     0          4           \n",
       "208     0          4           \n",
       "221     0          4           \n",
       "231     0          4           \n",
       "249     0          4           \n",
       "250     0          4           \n",
       "262     0          4           \n",
       "272     0          4           \n",
       "293     0          4           \n",
       "310     0          4           \n",
       "319     0          4           \n",
       "324     0          4           \n",
       "330     0          4           \n",
       "...    ..         ..           \n",
       "499653  4          0           \n",
       "499678  4          0           \n",
       "499693  4          0           \n",
       "499709  4          0           \n",
       "499712  4          0           \n",
       "499739  4          0           \n",
       "499753  4          0           \n",
       "499757  4          0           \n",
       "499769  4          0           \n",
       "499771  4          0           \n",
       "499789  4          0           \n",
       "499793  4          0           \n",
       "499794  4          0           \n",
       "499806  4          0           \n",
       "499816  4          0           \n",
       "499818  4          0           \n",
       "499824  4          0           \n",
       "499827  4          0           \n",
       "499836  4          0           \n",
       "499853  4          0           \n",
       "499861  4          0           \n",
       "499863  4          0           \n",
       "499877  4          0           \n",
       "499881  4          0           \n",
       "499923  4          0           \n",
       "499930  4          0           \n",
       "499937  4          0           \n",
       "499948  4          0           \n",
       "499963  4          0           \n",
       "499996  4          0           \n",
       "\n",
       "[33486 rows x 4 columns]"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "errors = (y_test != pd.Series(predictions, index=y_test.index))\n",
    "pd.concat([train_sample[['Text','Tokens']],y_test,pd.Series(predictions, index=y_test.index, name='Prediction')],sort=False,axis=1,join='inner').loc[errors[errors==True].sort_index().keys().tolist()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1,1, 10], 'intercept_scaling': [10,1,0.1,], 'solver': ['lbfgs', 'liblinear']} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(LogisticRegression(),param_grid,refit=True,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "[CV] C=0.1, intercept_scaling=10, solver=lbfgs .......................\n",
      "[CV]  C=0.1, intercept_scaling=10, solver=lbfgs, score=0.7791192025165642, total=   5.0s\n",
      "[CV] C=0.1, intercept_scaling=10, solver=lbfgs .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, intercept_scaling=10, solver=lbfgs, score=0.7769111098730141, total=   4.7s\n",
      "[CV] C=0.1, intercept_scaling=10, solver=lbfgs .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    9.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, intercept_scaling=10, solver=lbfgs, score=0.7775453964934236, total=   4.7s\n",
      "[CV] C=0.1, intercept_scaling=10, solver=liblinear ...................\n",
      "[CV]  C=0.1, intercept_scaling=10, solver=liblinear, score=0.7791363453247276, total=   8.0s\n",
      "[CV] C=0.1, intercept_scaling=10, solver=liblinear ...................\n",
      "[CV]  C=0.1, intercept_scaling=10, solver=liblinear, score=0.7769625385179122, total=   8.0s\n",
      "[CV] C=0.1, intercept_scaling=10, solver=liblinear ...................\n",
      "[CV]  C=0.1, intercept_scaling=10, solver=liblinear, score=0.7776182537403625, total=   8.3s\n",
      "[CV] C=0.1, intercept_scaling=1, solver=lbfgs ........................\n",
      "[CV]  C=0.1, intercept_scaling=1, solver=lbfgs, score=0.7791192025165642, total=   4.9s\n",
      "[CV] C=0.1, intercept_scaling=1, solver=lbfgs ........................\n",
      "[CV]  C=0.1, intercept_scaling=1, solver=lbfgs, score=0.7769111098730141, total=   4.7s\n",
      "[CV] C=0.1, intercept_scaling=1, solver=lbfgs ........................\n",
      "[CV]  C=0.1, intercept_scaling=1, solver=lbfgs, score=0.7775453964934236, total=   4.6s\n",
      "[CV] C=0.1, intercept_scaling=1, solver=liblinear ....................\n",
      "[CV]  C=0.1, intercept_scaling=1, solver=liblinear, score=0.7791192025165642, total=   8.1s\n",
      "[CV] C=0.1, intercept_scaling=1, solver=liblinear ....................\n",
      "[CV]  C=0.1, intercept_scaling=1, solver=liblinear, score=0.7769625385179122, total=   8.4s\n",
      "[CV] C=0.1, intercept_scaling=1, solver=liblinear ....................\n",
      "[CV]  C=0.1, intercept_scaling=1, solver=liblinear, score=0.7776096822995462, total=   8.5s\n",
      "[CV] C=0.1, intercept_scaling=0.1, solver=lbfgs ......................\n",
      "[CV]  C=0.1, intercept_scaling=0.1, solver=lbfgs, score=0.7791192025165642, total=   5.0s\n",
      "[CV] C=0.1, intercept_scaling=0.1, solver=lbfgs ......................\n",
      "[CV]  C=0.1, intercept_scaling=0.1, solver=lbfgs, score=0.7769111098730141, total=   4.8s\n",
      "[CV] C=0.1, intercept_scaling=0.1, solver=lbfgs ......................\n",
      "[CV]  C=0.1, intercept_scaling=0.1, solver=lbfgs, score=0.7775453964934236, total=   4.8s\n",
      "[CV] C=0.1, intercept_scaling=0.1, solver=liblinear ..................\n",
      "[CV]  C=0.1, intercept_scaling=0.1, solver=liblinear, score=0.7791963451532996, total=   8.3s\n",
      "[CV] C=0.1, intercept_scaling=0.1, solver=liblinear ..................\n",
      "[CV]  C=0.1, intercept_scaling=0.1, solver=liblinear, score=0.7770568243668919, total=   8.5s\n",
      "[CV] C=0.1, intercept_scaling=0.1, solver=liblinear ..................\n",
      "[CV]  C=0.1, intercept_scaling=0.1, solver=liblinear, score=0.7777682539546485, total=   8.4s\n",
      "[CV] C=1, intercept_scaling=10, solver=lbfgs .........................\n",
      "[CV]  C=1, intercept_scaling=10, solver=lbfgs, score=0.7789649172430936, total=   4.8s\n",
      "[CV] C=1, intercept_scaling=10, solver=lbfgs .........................\n",
      "[CV]  C=1, intercept_scaling=10, solver=lbfgs, score=0.7769111098730141, total=   4.9s\n",
      "[CV] C=1, intercept_scaling=10, solver=lbfgs .........................\n",
      "[CV]  C=1, intercept_scaling=10, solver=lbfgs, score=0.7777768253954649, total=   4.8s\n",
      "[CV] C=1, intercept_scaling=10, solver=liblinear .....................\n",
      "[CV]  C=1, intercept_scaling=10, solver=liblinear, score=0.7790463455818698, total=  10.7s\n",
      "[CV] C=1, intercept_scaling=10, solver=liblinear .....................\n",
      "[CV]  C=1, intercept_scaling=10, solver=liblinear, score=0.7768896812709732, total=  10.7s\n",
      "[CV] C=1, intercept_scaling=10, solver=liblinear .....................\n",
      "[CV]  C=1, intercept_scaling=10, solver=liblinear, score=0.7777939682770976, total=  10.9s\n",
      "[CV] C=1, intercept_scaling=1, solver=lbfgs ..........................\n",
      "[CV]  C=1, intercept_scaling=1, solver=lbfgs, score=0.7789649172430936, total=   4.8s\n",
      "[CV] C=1, intercept_scaling=1, solver=lbfgs ..........................\n",
      "[CV]  C=1, intercept_scaling=1, solver=lbfgs, score=0.7769111098730141, total=   4.9s\n",
      "[CV] C=1, intercept_scaling=1, solver=lbfgs ..........................\n",
      "[CV]  C=1, intercept_scaling=1, solver=lbfgs, score=0.7777768253954649, total=   4.6s\n",
      "[CV] C=1, intercept_scaling=1, solver=liblinear ......................\n",
      "[CV]  C=1, intercept_scaling=1, solver=liblinear, score=0.7790420598798289, total=  10.3s\n",
      "[CV] C=1, intercept_scaling=1, solver=liblinear ......................\n",
      "[CV]  C=1, intercept_scaling=1, solver=liblinear, score=0.7768982527117896, total=  11.1s\n",
      "[CV] C=1, intercept_scaling=1, solver=liblinear ......................\n",
      "[CV]  C=1, intercept_scaling=1, solver=liblinear, score=0.7777939682770976, total=  10.4s\n",
      "[CV] C=1, intercept_scaling=0.1, solver=lbfgs ........................\n",
      "[CV]  C=1, intercept_scaling=0.1, solver=lbfgs, score=0.7789649172430936, total=   4.8s\n",
      "[CV] C=1, intercept_scaling=0.1, solver=lbfgs ........................\n",
      "[CV]  C=1, intercept_scaling=0.1, solver=lbfgs, score=0.7769111098730141, total=   4.9s\n",
      "[CV] C=1, intercept_scaling=0.1, solver=lbfgs ........................\n",
      "[CV]  C=1, intercept_scaling=0.1, solver=lbfgs, score=0.7777768253954649, total=   4.6s\n",
      "[CV] C=1, intercept_scaling=0.1, solver=liblinear ....................\n",
      "[CV]  C=1, intercept_scaling=0.1, solver=liblinear, score=0.7790377741777881, total=  10.8s\n",
      "[CV] C=1, intercept_scaling=0.1, solver=liblinear ....................\n",
      "[CV]  C=1, intercept_scaling=0.1, solver=liblinear, score=0.7768939669913815, total=  10.7s\n",
      "[CV] C=1, intercept_scaling=0.1, solver=liblinear ....................\n",
      "[CV]  C=1, intercept_scaling=0.1, solver=liblinear, score=0.7777768253954649, total=  10.2s\n",
      "[CV] C=10, intercept_scaling=10, solver=lbfgs ........................\n",
      "[CV]  C=10, intercept_scaling=10, solver=lbfgs, score=0.778982060051257, total=   4.5s\n",
      "[CV] C=10, intercept_scaling=10, solver=lbfgs ........................\n",
      "[CV]  C=10, intercept_scaling=10, solver=lbfgs, score=0.7769411099158713, total=   4.7s\n",
      "[CV] C=10, intercept_scaling=10, solver=lbfgs ........................\n",
      "[CV]  C=10, intercept_scaling=10, solver=lbfgs, score=0.7778239683199547, total=   4.7s\n",
      "[CV] C=10, intercept_scaling=10, solver=liblinear ....................\n",
      "[CV]  C=10, intercept_scaling=10, solver=liblinear, score=0.7790334884757472, total=  14.5s\n",
      "[CV] C=10, intercept_scaling=10, solver=liblinear ....................\n",
      "[CV]  C=10, intercept_scaling=10, solver=liblinear, score=0.7768725383893406, total=  15.1s\n",
      "[CV] C=10, intercept_scaling=10, solver=liblinear ....................\n",
      "[CV]  C=10, intercept_scaling=10, solver=liblinear, score=0.7777939682770976, total=  14.3s\n",
      "[CV] C=10, intercept_scaling=1, solver=lbfgs .........................\n",
      "[CV]  C=10, intercept_scaling=1, solver=lbfgs, score=0.778982060051257, total=   4.5s\n",
      "[CV] C=10, intercept_scaling=1, solver=lbfgs .........................\n",
      "[CV]  C=10, intercept_scaling=1, solver=lbfgs, score=0.7769411099158713, total=   4.7s\n",
      "[CV] C=10, intercept_scaling=1, solver=lbfgs .........................\n",
      "[CV]  C=10, intercept_scaling=1, solver=lbfgs, score=0.7778239683199547, total=   4.7s\n",
      "[CV] C=10, intercept_scaling=1, solver=liblinear .....................\n",
      "[CV]  C=10, intercept_scaling=1, solver=liblinear, score=0.7790206313696246, total=  11.3s\n",
      "[CV] C=10, intercept_scaling=1, solver=liblinear .....................\n",
      "[CV]  C=10, intercept_scaling=1, solver=liblinear, score=0.7768725383893406, total=  11.7s\n",
      "[CV] C=10, intercept_scaling=1, solver=liblinear .....................\n",
      "[CV]  C=10, intercept_scaling=1, solver=liblinear, score=0.7777939682770976, total=  11.0s\n",
      "[CV] C=10, intercept_scaling=0.1, solver=lbfgs .......................\n",
      "[CV]  C=10, intercept_scaling=0.1, solver=lbfgs, score=0.778982060051257, total=   4.6s\n",
      "[CV] C=10, intercept_scaling=0.1, solver=lbfgs .......................\n",
      "[CV]  C=10, intercept_scaling=0.1, solver=lbfgs, score=0.7769411099158713, total=   4.7s\n",
      "[CV] C=10, intercept_scaling=0.1, solver=lbfgs .......................\n",
      "[CV]  C=10, intercept_scaling=0.1, solver=lbfgs, score=0.7778239683199547, total=   4.6s\n",
      "[CV] C=10, intercept_scaling=0.1, solver=liblinear ...................\n",
      "[CV]  C=10, intercept_scaling=0.1, solver=liblinear, score=0.7790206313696246, total=  11.1s\n",
      "[CV] C=10, intercept_scaling=0.1, solver=liblinear ...................\n",
      "[CV]  C=10, intercept_scaling=0.1, solver=liblinear, score=0.7768725383893406, total=  11.1s\n",
      "[CV] C=10, intercept_scaling=0.1, solver=liblinear ...................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=10, intercept_scaling=0.1, solver=liblinear, score=0.7777939682770976, total=  10.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed:  7.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.1, 1, 10], 'intercept_scaling': [10, 1, 0.1], 'solver': ['lbfgs', 'liblinear']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'intercept_scaling': 0.1}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.74      0.77    150146\n",
      "          4       0.76      0.81      0.78    149854\n",
      "\n",
      "avg / total       0.78      0.78      0.78    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7775533333333333\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
